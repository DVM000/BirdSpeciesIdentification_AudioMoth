function [Y,Xf,Af] = NeuralNetworkFunction(X,~,~)
%NEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 06-May-2025 06:34:24.
% 
% [Y] = NeuralNetworkFunction(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 24xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Layer 1
b1 = [1.8916010551494097935;2.0087474377775778045];
IW1_1 = [0.1998886754907664709 0.57158025640225418318 0.073053558551228664486 0.30815336956943989444 -0.36003003489407331417 0.35955390517506552461 -0.55180303576284406297 0.36854512746086781627 -0.11990989497331375202 -0.12415192057333071518 -0.11036941186308167617 0.17488461021140797036 -0.013529466284958970024 -0.14750359472676494166 0.055395201464141327619 0.37214938872552660865 -0.24550221656609863552 0.26630143218921387138 -0.47940732926561213656 -0.50824973434697218178 0.38211640719584838433 0.62598088027513776321 0.23283702476734549625 0.67685222502032615921;-0.58969760140591542807 0.13612969647931399964 0.28130343863305534713 0.44360322873237156838 0.025224012033459614068 -0.40590449389022426052 1.1143112752679664723 -0.2161903374887501339 0.23162703430932926607 -0.32741518794124441216 0.47349665037919996813 -0.45920452643889042577 -0.14105785899327966115 0.031379435557255155875 0.35720107620842272977 0.21229694142108621047 -0.20368656129300038993 0.1738414724904205344 -0.35063776391904794005 -0.6775042296727354918 -0.17173184806768476696 0.46230394894357262903 0.14771323500073230139 0.79802613525304866293];

% Layer 2
b2 = [-0.089268169590198245822;0.52228923760607492977];
LW2_1 = [-0.44486678654834321822 1.1688121908846942354;1.0641647684820378927 -0.85051800764122009735];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
  X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    % no processing
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*X{1,ts});
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
  Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
  if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
  else
    a = iSoftmaxApplyCPU(n);
  end
end
function a = iSoftmaxApplyCPU(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numerator = exp(n);
  denominator = sum(numerator,1); 
  denominator(denominator == 0) = 1;
  a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
  nmax = max(n,[],1);
  numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
  denominator = sum(numerator,1);
  a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
  numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
  if (denominator == 0)
    a = numerator;
  else
    a = numerator ./ denominator;
  end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end
