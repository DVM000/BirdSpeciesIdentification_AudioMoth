function [Y,Xf,Af] = NeuralNetworkFunction(X,~,~)
%NEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 06-Mar-2025 09:42:32.
% 
% [Y] = NeuralNetworkFunction(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 24xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Layer 1
b1 = [-1.6506595038998270741;1.0714025936080897594];
IW1_1 = [-0.14701604449555649712 0.012510029384784456669 -0.10765188152252687381 0.071180338776944462875 0.061337039759318652543 0.07557964594909946654 -0.052529524209502437282 -0.18343187601660726482 -0.028753465003183625859 0.14929364750239063064 -0.22476698332039823924 0.22934918030278503287 -0.05035400237997162548 -0.15055370722294802999 -0.3923630242629779219 -0.13481919076067130914 -0.63449351419339827807 0.56403213635115156954 0.21292134952589161778 0.057119735283437930717 -0.22679689855485193895 0.045036925887866785523 -0.32470570602237780466 -0.018139349505913043153;0.68511045408493331799 0.49584749848072662282 0.67755136527226134113 0.069789348142964946486 -0.48259518349628083289 0.31833828044030243465 -0.36685163332242770595 0.32092691603317674565 -0.031015556069871316747 -0.096091285828796710322 -0.19435447514644649258 -0.15616056365643254944 -0.15479064083304672206 -0.14544622046057389952 -0.029775084319359788887 -0.25126427067816187177 0.24481594574285836519 0.47007313654123988877 0.10662993499324295577 0.57975668297760285519 0.30475582538514162101 0.11974450165227325249 0.57213684340161352626 0.51677005424638533526];

% Layer 2
b2 = [0.71983910097112435711;0.42310377090373713083];
LW2_1 = [-0.14048335432837033565 -1.3336896431931430929;-0.35913970340071038612 0.34787595174652785612];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
  X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    % no processing
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*X{1,ts});
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
  Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
  if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
  else
    a = iSoftmaxApplyCPU(n);
  end
end
function a = iSoftmaxApplyCPU(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numerator = exp(n);
  denominator = sum(numerator,1); 
  denominator(denominator == 0) = 1;
  a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
  nmax = max(n,[],1);
  numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
  denominator = sum(numerator,1);
  a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
  numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
  if (denominator == 0)
    a = numerator;
  else
    a = numerator ./ denominator;
  end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end
